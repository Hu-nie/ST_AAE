{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from model import *\n",
    "from utils import *\n",
    "\n",
    "# System Parameters\n",
    "# 1. Mini batch size\n",
    "mb_size = 128\n",
    "# 2. Missing rate\n",
    "p_miss = 0.2\n",
    "# 3. Hint rate\n",
    "p_hint = 0\n",
    "# 4. Loss Hyperparameters\n",
    "alpha = 10\n",
    "# 5. Train Rate\n",
    "train_rate = 0.8\n",
    "\n",
    "#% Data\n",
    "dataset_file = 'data/V_228.csv'\n",
    "# Data generation\n",
    "Data = np.loadtxt(dataset_file, delimiter=\",\",skiprows=1)\n",
    "\n",
    "# Parameters\n",
    "No = len(Data)\n",
    "Dim = len(Data[0,:])\n",
    "\n",
    "# Hidden state dimensions\n",
    "H_Dim1 = Dim\n",
    "H_Dim2 = Dim\n",
    "\n",
    "# Normalization (0 to 1)\n",
    "Min_Val = np.zeros(Dim)\n",
    "Max_Val = np.zeros(Dim)\n",
    "\n",
    "for i in range(Dim):\n",
    "    Min_Val[i] = np.min(Data[:,i])\n",
    "    #print(np.min(Data[:,i]))\n",
    "    Data[:,i] = Data[:,i] - np.min(Data[:,i])\n",
    "    Max_Val[i] = np.max(Data[:,i])\n",
    "    Data[:,i] = Data[:,i] / (np.max(Data[:,i]) + 1e-6)    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# Missing introducing\n",
    "p_miss_vec = p_miss * np.ones((Dim,1)) \n",
    "   \n",
    "Missing = np.zeros((No,Dim))\n",
    "\n",
    "for i in range(Dim):\n",
    "    A = np.random.uniform(0., 1., size = [len(Data),])\n",
    "    B = A > p_miss_vec[i]\n",
    "    Missing[:,i] = 1.*B\n",
    "\n",
    "    \n",
    "# Train Test Division    \n",
    "   \n",
    "idx = np.random.permutation(No)\n",
    "\n",
    "Train_No = int(No * train_rate)\n",
    "Test_No = No - Train_No\n",
    "    \n",
    "# Train / Test Features\n",
    "trainX = Data[idx[:Train_No],:]\n",
    "testX = Data[idx[Train_No:],:]\n",
    "\n",
    "# Train / Test Missing Indicators\n",
    "trainM = Missing[idx[:Train_No],:]\n",
    "testM = Missing[idx[Train_No:],:]\n",
    "\n",
    "netD = NetD()\n",
    "netG = NetG()\n",
    "\n",
    "\n",
    "optimD = torch.optim.Adam(netD.parameters(), lr=0.001)\n",
    "optimG = torch.optim.Adam(netG.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "bce_loss = torch.nn.BCEWithLogitsLoss(reduction=\"elementwise_mean\")\n",
    "mse_loss = torch.nn.MSELoss(reduction=\"elementwise_mean\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/_reduction.py:13: UserWarning: reduction='elementwise_mean' is deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(\"reduction='elementwise_mean' is deprecated, please use reduction='mean' instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0\tTrain_loss: 0.3516\tTest_loss: 0.3513\tG_loss: 1.236\tD_loss: 0.5771\n",
      "Iter: 100\tTrain_loss: 0.1074\tTest_loss: 0.108\tG_loss: 0.1153\tD_loss: 0.5152\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-50ac2781a74a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mG_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG_loss1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mG_mse_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mG_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0moptimG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0moptimG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "# Start Iterations\n",
    "for it in range(5000): \n",
    "    #%% Inputs\n",
    "    mb_idx = sample_idx(Train_No, mb_size)\n",
    "    X_mb = trainX[mb_idx,:]  \n",
    "\n",
    "    Z_mb = sample_Z(mb_size, Dim) \n",
    "    M_mb = trainM[mb_idx,:]  \n",
    "    H_mb1 = sample_M(mb_size, Dim, 1-p_hint)\n",
    "    H_mb = M_mb * H_mb1 \n",
    "    \n",
    "    New_X_mb = M_mb * X_mb + (1-M_mb) * Z_mb  # Missing Data Introduce\n",
    "    \n",
    "    X_mb = torch.tensor(X_mb).float()\n",
    "    New_X_mb = torch.tensor(New_X_mb).float()\n",
    "    Z_mb = torch.tensor(Z_mb).float()\n",
    "    M_mb = torch.tensor(M_mb).float()\n",
    "    H_mb = torch.tensor(H_mb).float()\n",
    "    \n",
    "    # Train D\n",
    "    G_sample = netG(X_mb, New_X_mb, M_mb)\n",
    "    D_prob = netD(X_mb, M_mb, G_sample, H_mb)\n",
    "    D_loss = bce_loss(D_prob, M_mb)\n",
    "\n",
    "    optimD.zero_grad()\n",
    "    D_loss.backward()\n",
    "    optimD.step()\n",
    "    \n",
    "    \n",
    "    # Train G\n",
    "    G_sample = netG(X_mb, New_X_mb, M_mb)\n",
    "    D_prob = netD(X_mb, M_mb, G_sample, H_mb)\n",
    "    D_prob.detach_()\n",
    "    G_loss1 = ((1 - M_mb) * (torch.sigmoid(D_prob)+1e-8).log()).mean()/(1-M_mb).sum()\n",
    "    G_mse_loss = mse_loss(M_mb*X_mb, M_mb*G_sample) / M_mb.sum()\n",
    "    G_loss = G_loss1 + alpha*G_mse_loss\n",
    "    \n",
    "    G_loss.backward()\n",
    "    optimG.step()\n",
    "    optimG.zero_grad()\n",
    "    \n",
    "    G_mse_test = mse_loss((1-M_mb)*X_mb, (1-M_mb)*G_sample) / (1-M_mb).sum()\n",
    "\n",
    "\n",
    "    if it % 100 == 0:\n",
    "        print('Iter: {}'.format(it),end='\\t')\n",
    "        print('Train_loss: {:.4}'.format(np.sqrt(G_mse_loss.item())),end='\\t')\n",
    "        print('Test_loss: {:.4}'.format(np.sqrt(G_mse_test.item())),end='\\t')\n",
    "        print('G_loss: {:.4}'.format(G_loss),end='\\t')\n",
    "        print('D_loss: {:.4}'.format(D_loss))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "G_sample = netG(X_mb, New_X_mb, M_mb)\n",
    "\n",
    "Z_mb = sample_Z(Test_No, Dim) \n",
    "M_mb = testM\n",
    "X_mb = testX\n",
    "        \n",
    "New_X_mb = M_mb * X_mb + (1-M_mb) * Z_mb  # Missing Data Introduce\n",
    "\n",
    "X_mb = torch.tensor(X_mb).float()\n",
    "M_mb = torch.tensor(M_mb).float()\n",
    "New_X_mb = torch.tensor(New_X_mb).float()\n",
    "\n",
    "\n",
    "\n",
    "imputed_data = M_mb * X_mb + (1-M_mb) * G_sample\n",
    "\n",
    "# Normalization (0 to 1)\n",
    "for i in range(Dim):\n",
    "    imputed_data[:,i] = imputed_data[:,i]* (Max_Val[i]+1e-6)\n",
    "    imputed_data[:,i] = imputed_data[:,i]+ Min_Val[i]\n",
    "    \n",
    "renomal = imputed_data.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "renomal_df = pd.DataFrame(renomal)\n",
    " \n",
    "renomal_df.to_csv('sample.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mb_df = X_mb.detach().numpy()\n",
    "Actual_df = X_mb.detach().numpy()\n",
    "for i in range(Dim):\n",
    "    X_mb_df[:,i] = X_mb_df[:,i]* (Max_Val[i]+1e-6)\n",
    "    X_mb_df[:,i] = X_mb_df[:,i]+ Min_Val[i]\n",
    "\n",
    "import pandas as pd\n",
    "X_mb_df = pd.DataFrame(X_mb_df)\n",
    " \n",
    "X_mb_df.to_csv('sample1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean 방식\n",
    "Actual_df = testM * testX \n",
    "Actual_df = pd.DataFrame(Actual_df)\n",
    "Actual_df = Actual_df.replace(0, np.NaN)\n",
    "\n",
    "import impyute as impy\n",
    "np_imputed=impy.mean(Actual_df)\n",
    "np_imputed = np_imputed.to_numpy()\n",
    "for i in range(Dim):\n",
    "    np_imputed[:,i] = np_imputed[:,i]* (Max_Val[i]+1e-6)\n",
    "    np_imputed[:,i] = np_imputed[:,i]+ Min_Val[i]\n",
    "\n",
    "mean_imputed = pd.DataFrame(np_imputed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "%matplotlib inline \n",
    "\n",
    "import seaborn as sns\n",
    "X_mb_df = X_mb_df.rolling(window=5).mean()\n",
    "renomal_df = renomal_df.rolling(window=5).mean()\n",
    "mean_imputed = mean_imputed.rolling(window=5).mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'axes.labelsize': 25,'axes.titlesize': 35,'legend.fontsize':25,'xtick.labelsize':25,'ytick.labelsize':25}\n",
    "plt.rcParams.update(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.xlabel('Time(5m)')\n",
    "plt.ylabel('Speed(Km/s)')\n",
    "\n",
    "plt.plot(X_mb_df[0][:300],label='Actual',color='r',linestyle='-',linewidth=5.0)\n",
    "plt.plot(renomal_df[0][:300],label='GAIN',color='b',linestyle=':',linewidth=5.0)\n",
    "plt.plot(mean_imputed[0][:300],label='Our',color='g',linestyle='--',linewidth=5.0)\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

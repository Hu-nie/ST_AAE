{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3536fd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Packages\n",
    "import torch\n",
    "import numpy as np\n",
    "# from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c4073d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_file = 'V_228.csv'  # 'Letter.csv' for Letter dataset an 'Spam.csv' for Spam dataset\n",
    "use_gpu = False  # set it to True to use GPU and False to use CPU\n",
    "\n",
    "if use_gpu:\n",
    "    torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec154df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12671\n",
      "3.3\n",
      "5.0\n",
      "12.3\n",
      "20.3\n",
      "12.3\n",
      "7.0\n",
      "4.2\n",
      "7.0\n",
      "17.7\n",
      "8.6\n",
      "9.5\n",
      "10.6\n",
      "17.9\n",
      "36.1\n",
      "10.5\n",
      "4.0\n",
      "11.6\n",
      "11.8\n",
      "10.3\n",
      "15.9\n",
      "5.5\n",
      "7.7\n",
      "3.8\n",
      "5.7\n",
      "4.4\n",
      "4.8\n",
      "3.9\n",
      "6.3\n",
      "8.1\n",
      "15.9\n",
      "5.3\n",
      "7.0\n",
      "5.0\n",
      "3.0\n",
      "5.6\n",
      "5.0\n",
      "5.2\n",
      "6.0\n",
      "3.0\n",
      "5.4\n",
      "10.5\n",
      "21.4\n",
      "10.7\n",
      "3.8\n",
      "20.3\n",
      "6.5\n",
      "5.3\n",
      "3.0\n",
      "3.0\n",
      "8.9\n",
      "8.9\n",
      "7.7\n",
      "3.0\n",
      "4.6\n",
      "12.3\n",
      "3.4\n",
      "14.1\n",
      "6.7\n",
      "9.7\n",
      "3.7\n",
      "3.0\n",
      "4.6\n",
      "34.3\n",
      "21.0\n",
      "8.9\n",
      "11.8\n",
      "25.4\n",
      "13.5\n",
      "9.1\n",
      "9.9\n",
      "6.3\n",
      "3.2\n",
      "4.8\n",
      "3.1\n",
      "4.7\n",
      "8.0\n",
      "17.9\n",
      "19.8\n",
      "14.2\n",
      "7.2\n",
      "12.7\n",
      "7.1\n",
      "6.8\n",
      "8.0\n",
      "5.3\n",
      "12.9\n",
      "42.8\n",
      "5.2\n",
      "9.6\n",
      "9.4\n",
      "11.1\n",
      "18.1\n",
      "18.6\n",
      "13.9\n",
      "4.4\n",
      "10.3\n",
      "12.6\n",
      "14.5\n",
      "7.5\n",
      "4.3\n",
      "13.5\n",
      "8.2\n",
      "6.3\n",
      "15.3\n",
      "10.3\n",
      "14.0\n",
      "8.5\n",
      "20.7\n",
      "9.0\n",
      "25.8\n",
      "20.0\n",
      "9.4\n",
      "11.0\n",
      "3.5\n",
      "6.2\n",
      "31.4\n",
      "12.0\n",
      "9.4\n",
      "4.9\n",
      "6.9\n",
      "14.7\n",
      "15.8\n",
      "12.1\n",
      "15.8\n",
      "18.9\n",
      "8.0\n",
      "11.1\n",
      "8.9\n",
      "5.6\n",
      "4.0\n",
      "26.9\n",
      "19.8\n",
      "10.6\n",
      "17.8\n",
      "28.1\n",
      "19.9\n",
      "9.1\n",
      "5.8\n",
      "25.4\n",
      "22.8\n",
      "8.5\n",
      "19.8\n",
      "7.2\n",
      "6.3\n",
      "25.0\n",
      "19.7\n",
      "20.0\n",
      "5.8\n",
      "6.6\n",
      "6.0\n",
      "6.0\n",
      "23.5\n",
      "12.1\n",
      "4.8\n",
      "4.6\n",
      "4.6\n",
      "21.1\n",
      "13.5\n",
      "8.7\n",
      "8.3\n",
      "8.2\n",
      "6.8\n",
      "15.8\n",
      "3.9\n",
      "3.0\n",
      "5.5\n",
      "6.1\n",
      "27.9\n",
      "8.9\n",
      "14.1\n",
      "11.4\n",
      "7.6\n",
      "13.1\n",
      "8.6\n",
      "8.2\n",
      "5.5\n",
      "4.7\n",
      "7.4\n",
      "6.9\n",
      "8.8\n",
      "6.9\n",
      "8.9\n",
      "10.7\n",
      "5.8\n",
      "6.0\n",
      "7.2\n",
      "11.7\n",
      "5.0\n",
      "4.4\n",
      "9.2\n",
      "8.8\n",
      "4.9\n",
      "3.7\n",
      "22.5\n",
      "11.2\n",
      "4.5\n",
      "9.9\n",
      "4.8\n",
      "4.0\n",
      "6.9\n",
      "13.8\n",
      "8.3\n",
      "4.7\n",
      "6.1\n",
      "20.5\n",
      "3.5\n",
      "4.3\n",
      "20.3\n",
      "12.3\n",
      "4.0\n",
      "13.5\n",
      "20.2\n",
      "5.8\n",
      "5.8\n",
      "7.3\n",
      "16.5\n",
      "9.3\n",
      "22.0\n",
      "18.3\n",
      "6.4\n",
      "14.3\n",
      "13.2\n",
      "4.8\n",
      "17.7\n",
      "3.3\n",
      "8.3\n",
      "9.7\n",
      "7.8\n"
     ]
    }
   ],
   "source": [
    "#%% System Parameters\n",
    "# 1. Mini batch size\n",
    "mb_size = 128\n",
    "# 2. Missing rate\n",
    "p_miss = 0.2\n",
    "# 3. Hint rate\n",
    "p_hint = 0\n",
    "# 4. Loss Hyperparameters\n",
    "alpha = 10\n",
    "# 5. Train Rate\n",
    "train_rate = 0.8\n",
    "\n",
    "#%% Data\n",
    "\n",
    "# Data generation\n",
    "Data = np.loadtxt(dataset_file, delimiter=\",\",skiprows=1)\n",
    "\n",
    "# Parameters\n",
    "No = len(Data)\n",
    "Dim = len(Data[0,:])\n",
    "#print(len(Data))\n",
    "\n",
    "# Hidden state dimensions\n",
    "H_Dim1 = Dim\n",
    "H_Dim2 = Dim\n",
    "\n",
    "# Normalization (0 to 1)\n",
    "Min_Val = np.zeros(Dim)\n",
    "Max_Val = np.zeros(Dim)\n",
    "\n",
    "for i in range(Dim):\n",
    "    Min_Val[i] = np.min(Data[:,i])\n",
    "    #print(np.min(Data[:,i]))\n",
    "    Data[:,i] = Data[:,i] - np.min(Data[:,i])\n",
    "    Max_Val[i] = np.max(Data[:,i])\n",
    "    Data[:,i] = Data[:,i] / (np.max(Data[:,i]) + 1e-6)    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#%% Missing introducing\n",
    "p_miss_vec = p_miss * np.ones((Dim,1)) \n",
    "   \n",
    "Missing = np.zeros((No,Dim))\n",
    "\n",
    "for i in range(Dim):\n",
    "    A = np.random.uniform(0., 1., size = [len(Data),])\n",
    "    B = A > p_miss_vec[i]\n",
    "    Missing[:,i] = 1.*B\n",
    "\n",
    "    \n",
    "#%% Train Test Division    \n",
    "   \n",
    "idx = np.random.permutation(No)\n",
    "\n",
    "Train_No = int(No * train_rate)\n",
    "Test_No = No - Train_No\n",
    "    \n",
    "# Train / Test Features\n",
    "trainX = Data[idx[:Train_No],:]\n",
    "testX = Data[idx[Train_No:],:]\n",
    "\n",
    "# Train / Test Missing Indicators\n",
    "trainM = Missing[idx[:Train_No],:]\n",
    "testM = Missing[idx[Train_No:],:]\n",
    "\n",
    "#%% Necessary Functions\n",
    "\n",
    "# 1. Xavier Initialization Definition\n",
    "# def xavier_init(size):\n",
    "#     in_dim = size[0]\n",
    "#     xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
    "#     return tf.random_normal(shape = size, stddev = xavier_stddev)\n",
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1. / np.sqrt(in_dim / 2.)\n",
    "    return np.random.normal(size = size, scale = xavier_stddev)\n",
    "    \n",
    "# Hint Vector Generation\n",
    "def sample_M(m, n, p):\n",
    "    A = np.random.uniform(0., 1., size = [m, n])\n",
    "    B = A > p\n",
    "    C = 1.*B\n",
    "    return C\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60be4a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% 3. Other functions\n",
    "# Random sample generator for Z\n",
    "def sample_Z(m, n):\n",
    "    return np.random.uniform(0., 0.01, size = [m, n])        \n",
    "\n",
    "# Mini-batch generation\n",
    "def sample_idx(m, n):\n",
    "    A = np.random.permutation(m)\n",
    "    idx = A[:n]\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5658a7dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected Tensor as element 0 in argument 0, but got numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-2aff5101fa7c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mNew_X_mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mM_mb\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mX_mb\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mM_mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mZ_mb\u001b[0m  \u001b[1;31m# Missing Data Introduce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mNew_X_mb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mM_mb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Mask + Data Concatenate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected Tensor as element 0 in argument 0, but got numpy.ndarray"
     ]
    }
   ],
   "source": [
    "#%% Inputs\n",
    "mb_idx = sample_idx(Train_No, mb_size)\n",
    "X_mb = trainX[mb_idx,:]  \n",
    "    \n",
    "Z_mb = sample_Z(mb_size, Dim) \n",
    "M_mb = trainM[mb_idx,:]  \n",
    "H_mb1 = sample_M(mb_size, Dim, 1-p_hint)\n",
    "H_mb = M_mb * H_mb1\n",
    "    \n",
    "New_X_mb = M_mb * X_mb + (1-M_mb) * Z_mb  # Missing Data Introduce\n",
    "inputs = torch.cat(dim = 1, tensors = [New_X_mb,M_mb])  # Mask + Data Concatenate\n",
    "print(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369c6901",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(new_x,m):\n",
    "    inputs = torch.cat(dim = 1, tensors = [new_x,m])  # Mask + Data Concatenate\n",
    "    G_h1 = F.relu(torch.matmul(inputs, G_W1) + G_b1)\n",
    "    G_h2 = F.relu(torch.matmul(G_h1, G_W2) + G_b2)   \n",
    "    G_prob = torch.sigmoid(torch.matmul(G_h2, G_W3) + G_b3) # [0,1] normalized Output\n",
    "    \n",
    "    return G_prob"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch1",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

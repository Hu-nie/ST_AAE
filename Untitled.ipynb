{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/_reduction.py:13: UserWarning: reduction='elementwise_mean' is deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(\"reduction='elementwise_mean' is deprecated, please use reduction='mean' instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0\tTrain_loss: 0.3443\tTest_loss: 0.3436\tG_loss: 1.185\tD_loss: 0.713\n",
      "Iter: 100\tTrain_loss: 0.1083\tTest_loss: 0.1126\tG_loss: 0.1174\tD_loss: 0.4858\n",
      "Iter: 200\tTrain_loss: 0.1125\tTest_loss: 0.1159\tG_loss: 0.1265\tD_loss: 0.466\n",
      "Iter: 300\tTrain_loss: 0.1063\tTest_loss: 0.1083\tG_loss: 0.1129\tD_loss: 0.4512\n",
      "Iter: 400\tTrain_loss: 0.09721\tTest_loss: 0.1032\tG_loss: 0.09449\tD_loss: 0.4251\n",
      "Iter: 500\tTrain_loss: 0.09417\tTest_loss: 0.1023\tG_loss: 0.08867\tD_loss: 0.4025\n",
      "Iter: 600\tTrain_loss: 0.08802\tTest_loss: 0.09052\tG_loss: 0.07747\tD_loss: 0.3964\n",
      "Iter: 700\tTrain_loss: 0.08705\tTest_loss: 0.09447\tG_loss: 0.07576\tD_loss: 0.3903\n",
      "Iter: 800\tTrain_loss: 0.09043\tTest_loss: 0.1003\tG_loss: 0.08176\tD_loss: 0.3815\n",
      "Iter: 900\tTrain_loss: 0.0805\tTest_loss: 0.08787\tG_loss: 0.06478\tD_loss: 0.3657\n",
      "Iter: 1000\tTrain_loss: 0.08495\tTest_loss: 0.09243\tG_loss: 0.07215\tD_loss: 0.3677\n",
      "Iter: 1100\tTrain_loss: 0.08166\tTest_loss: 0.09152\tG_loss: 0.06665\tD_loss: 0.3603\n",
      "Iter: 1200\tTrain_loss: 0.08388\tTest_loss: 0.09598\tG_loss: 0.07034\tD_loss: 0.3537\n",
      "Iter: 1300\tTrain_loss: 0.08362\tTest_loss: 0.09677\tG_loss: 0.0699\tD_loss: 0.3606\n",
      "Iter: 1400\tTrain_loss: 0.08407\tTest_loss: 0.09605\tG_loss: 0.07065\tD_loss: 0.3604\n",
      "Iter: 1500\tTrain_loss: 0.07598\tTest_loss: 0.09185\tG_loss: 0.0577\tD_loss: 0.3475\n",
      "Iter: 1600\tTrain_loss: 0.07658\tTest_loss: 0.09349\tG_loss: 0.05862\tD_loss: 0.348\n",
      "Iter: 1700\tTrain_loss: 0.07581\tTest_loss: 0.08877\tG_loss: 0.05745\tD_loss: 0.3497\n",
      "Iter: 1800\tTrain_loss: 0.069\tTest_loss: 0.08571\tG_loss: 0.04759\tD_loss: 0.347\n",
      "Iter: 1900\tTrain_loss: 0.07272\tTest_loss: 0.09082\tG_loss: 0.05286\tD_loss: 0.3376\n",
      "Iter: 2000\tTrain_loss: 0.07104\tTest_loss: 0.08783\tG_loss: 0.05044\tD_loss: 0.3453\n",
      "Iter: 2100\tTrain_loss: 0.06586\tTest_loss: 0.08537\tG_loss: 0.04335\tD_loss: 0.3465\n",
      "Iter: 2200\tTrain_loss: 0.07276\tTest_loss: 0.09361\tG_loss: 0.05292\tD_loss: 0.3387\n",
      "Iter: 2300\tTrain_loss: 0.07025\tTest_loss: 0.09314\tG_loss: 0.04932\tD_loss: 0.3441\n",
      "Iter: 2400\tTrain_loss: 0.06623\tTest_loss: 0.08684\tG_loss: 0.04384\tD_loss: 0.34\n",
      "Iter: 2500\tTrain_loss: 0.06977\tTest_loss: 0.09098\tG_loss: 0.04865\tD_loss: 0.3399\n",
      "Iter: 2600\tTrain_loss: 0.06771\tTest_loss: 0.09079\tG_loss: 0.04582\tD_loss: 0.3378\n",
      "Iter: 2700\tTrain_loss: 0.06349\tTest_loss: 0.08334\tG_loss: 0.04028\tD_loss: 0.3416\n",
      "Iter: 2800\tTrain_loss: 0.06516\tTest_loss: 0.08791\tG_loss: 0.04242\tD_loss: 0.3372\n",
      "Iter: 2900\tTrain_loss: 0.06765\tTest_loss: 0.0942\tG_loss: 0.04574\tD_loss: 0.3402\n",
      "Iter: 3000\tTrain_loss: 0.0649\tTest_loss: 0.09368\tG_loss: 0.0421\tD_loss: 0.3394\n",
      "Iter: 3100\tTrain_loss: 0.06306\tTest_loss: 0.09145\tG_loss: 0.03974\tD_loss: 0.3338\n",
      "Iter: 3200\tTrain_loss: 0.06523\tTest_loss: 0.09212\tG_loss: 0.04252\tD_loss: 0.3387\n",
      "Iter: 3300\tTrain_loss: 0.06448\tTest_loss: 0.08842\tG_loss: 0.04155\tD_loss: 0.3358\n",
      "Iter: 3400\tTrain_loss: 0.05763\tTest_loss: 0.08217\tG_loss: 0.03319\tD_loss: 0.3423\n",
      "Iter: 3500\tTrain_loss: 0.06135\tTest_loss: 0.09174\tG_loss: 0.03761\tD_loss: 0.3363\n",
      "Iter: 3600\tTrain_loss: 0.06084\tTest_loss: 0.0884\tG_loss: 0.03699\tD_loss: 0.3402\n",
      "Iter: 3700\tTrain_loss: 0.06017\tTest_loss: 0.09091\tG_loss: 0.03618\tD_loss: 0.3331\n",
      "Iter: 3800\tTrain_loss: 0.05905\tTest_loss: 0.09266\tG_loss: 0.03484\tD_loss: 0.3262\n",
      "Iter: 3900\tTrain_loss: 0.06072\tTest_loss: 0.09307\tG_loss: 0.03684\tD_loss: 0.3268\n",
      "Iter: 4000\tTrain_loss: 0.05911\tTest_loss: 0.09332\tG_loss: 0.03491\tD_loss: 0.3275\n",
      "Iter: 4100\tTrain_loss: 0.05918\tTest_loss: 0.09232\tG_loss: 0.03499\tD_loss: 0.3344\n",
      "Iter: 4200\tTrain_loss: 0.05873\tTest_loss: 0.09646\tG_loss: 0.03446\tD_loss: 0.3298\n",
      "Iter: 4300\tTrain_loss: 0.06051\tTest_loss: 0.09525\tG_loss: 0.03658\tD_loss: 0.3388\n",
      "Iter: 4400\tTrain_loss: 0.05812\tTest_loss: 0.09846\tG_loss: 0.03375\tD_loss: 0.3281\n",
      "Iter: 4500\tTrain_loss: 0.05841\tTest_loss: 0.1004\tG_loss: 0.03409\tD_loss: 0.3337\n",
      "Iter: 4600\tTrain_loss: 0.05713\tTest_loss: 0.09706\tG_loss: 0.0326\tD_loss: 0.3338\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-7d3039193065>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0mD_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbce_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM_mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0moptimD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[0mD_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0moptimD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from model import *\n",
    "from utils import *\n",
    "\n",
    "# System Parameters\n",
    "# 1. Mini batch size\n",
    "mb_size = 128\n",
    "# 2. Missing rate\n",
    "p_miss = 0.2\n",
    "# 3. Hint rate\n",
    "p_hint = 0.9\n",
    "# 4. Loss Hyperparameters\n",
    "alpha = 10\n",
    "# 5. Train Rate\n",
    "train_rate = 0.8\n",
    "\n",
    "#% Data\n",
    "dataset_file = 'data/V_228.csv'\n",
    "# Data generation\n",
    "Data = np.loadtxt(dataset_file, delimiter=\",\",skiprows=1)\n",
    "\n",
    "# Parameters\n",
    "No = len(Data)\n",
    "Dim = len(Data[0,:])\n",
    "\n",
    "# Hidden state dimensions\n",
    "H_Dim1 = Dim\n",
    "H_Dim2 = Dim\n",
    "\n",
    "# Normalization (0 to 1)\n",
    "Min_Val = np.zeros(Dim)\n",
    "Max_Val = np.zeros(Dim)\n",
    "\n",
    "for i in range(Dim):\n",
    "    Min_Val[i] = np.min(Data[:,i])\n",
    "    #print(np.min(Data[:,i]))\n",
    "    Data[:,i] = Data[:,i] - np.min(Data[:,i])\n",
    "    Max_Val[i] = np.max(Data[:,i])\n",
    "    Data[:,i] = Data[:,i] / (np.max(Data[:,i]) + 1e-6)    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# Missing introducing\n",
    "p_miss_vec = p_miss * np.ones((Dim,1)) \n",
    "   \n",
    "Missing = np.zeros((No,Dim))\n",
    "\n",
    "for i in range(Dim):\n",
    "    A = np.random.uniform(0., 1., size = [len(Data),])\n",
    "    B = A > p_miss_vec[i]\n",
    "    Missing[:,i] = 1.*B\n",
    "\n",
    "    \n",
    "# Train Test Division    \n",
    "   \n",
    "idx = np.random.permutation(No)\n",
    "\n",
    "Train_No = int(No * train_rate)\n",
    "Test_No = No - Train_No\n",
    "    \n",
    "# Train / Test Features\n",
    "trainX = Data[idx[:Train_No],:]\n",
    "testX = Data[idx[Train_No:],:]\n",
    "\n",
    "# Train / Test Missing Indicators\n",
    "trainM = Missing[idx[:Train_No],:]\n",
    "testM = Missing[idx[Train_No:],:]\n",
    "\n",
    "netD = NetD()\n",
    "netG = NetG()\n",
    "\n",
    "\n",
    "optimD = torch.optim.Adam(netD.parameters(), lr=0.001)\n",
    "optimG = torch.optim.Adam(netG.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "bce_loss = torch.nn.BCEWithLogitsLoss(reduction=\"elementwise_mean\")\n",
    "mse_loss = torch.nn.MSELoss(reduction=\"elementwise_mean\")\n",
    "\n",
    "\n",
    "i = 1\n",
    "# Start Iterations\n",
    "for it in range(5000): \n",
    "    #%% Inputs\n",
    "    mb_idx = sample_idx(Train_No, mb_size)\n",
    "    X_mb = trainX[mb_idx,:]  \n",
    "\n",
    "    Z_mb = sample_Z(mb_size, Dim) \n",
    "    M_mb = trainM[mb_idx,:]  \n",
    "    H_mb1 = sample_M(mb_size, Dim, 1-p_hint)\n",
    "    H_mb = M_mb * H_mb1 \n",
    "    \n",
    "    New_X_mb = M_mb * X_mb + (1-M_mb) * Z_mb  # Missing Data Introduce\n",
    "    \n",
    "    X_mb = torch.tensor(X_mb).float()\n",
    "    New_X_mb = torch.tensor(New_X_mb).float()\n",
    "    Z_mb = torch.tensor(Z_mb).float()\n",
    "    M_mb = torch.tensor(M_mb).float()\n",
    "    H_mb = torch.tensor(H_mb).float()\n",
    "    \n",
    "    # Train D\n",
    "    G_sample = netG(X_mb, New_X_mb, M_mb)\n",
    "    D_prob = netD(X_mb, M_mb, G_sample, H_mb)\n",
    "    D_loss = bce_loss(D_prob, M_mb)\n",
    "\n",
    "    optimD.zero_grad()\n",
    "    D_loss.backward()\n",
    "    optimD.step()\n",
    "    \n",
    "    \n",
    "    # Train G\n",
    "    G_sample = netG(X_mb, New_X_mb, M_mb)\n",
    "    D_prob = netD(X_mb, M_mb, G_sample, H_mb)\n",
    "    D_prob.detach_()\n",
    "    G_loss1 = ((1 - M_mb) * (torch.sigmoid(D_prob)+1e-8).log()).mean()/(1-M_mb).sum()\n",
    "    G_mse_loss = mse_loss(M_mb*X_mb, M_mb*G_sample) / M_mb.sum()\n",
    "    G_loss = G_loss1 + alpha*G_mse_loss\n",
    "    \n",
    "    G_loss.backward()\n",
    "    optimG.step()\n",
    "    optimG.zero_grad()\n",
    "    \n",
    "    G_mse_test = mse_loss((1-M_mb)*X_mb, (1-M_mb)*G_sample) / (1-M_mb).sum()\n",
    "\n",
    "\n",
    "    if it % 100 == 0:\n",
    "        print('Iter: {}'.format(it),end='\\t')\n",
    "        print('Train_loss: {:.4}'.format(np.sqrt(G_mse_loss.item())),end='\\t')\n",
    "        print('Test_loss: {:.4}'.format(np.sqrt(G_mse_test.item())),end='\\t')\n",
    "        print('G_loss: {:.4}'.format(G_loss),end='\\t')\n",
    "        print('D_loss: {:.4}'.format(D_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test RMSE: 0.0931326287300339\n"
     ]
    }
   ],
   "source": [
    "def test_loss(X, M):\n",
    "    \n",
    "    \n",
    "    #%% MSE Performance metric\n",
    "    MSE_test_loss = torch.mean(((1-M) * X - (1-M)*G_sample)**2) / torch.mean(1-M)\n",
    "    return MSE_test_loss\n",
    "\n",
    "G_sample = netG(X_mb, New_X_mb, M_mb)\n",
    "\n",
    "Z_mb = sample_Z(Test_No, Dim) \n",
    "M_mb = testM\n",
    "X_mb = testX\n",
    "        \n",
    "New_X_mb = M_mb * X_mb + (1-M_mb) * Z_mb  # Missing Data Introduce\n",
    "\n",
    "X_mb = torch.tensor(X_mb).float()\n",
    "M_mb = torch.tensor(M_mb).float()\n",
    "New_X_mb = torch.tensor(New_X_mb).float()\n",
    "\n",
    "MSE_final= test_loss(X=X_mb, M=M_mb)\n",
    "print('Final Test RMSE: ' + str(np.sqrt(MSE_final.item())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed test data:\n",
      "[[0.24097937 0.18885008 0.66421413 ... 0.73685551 0.78604650 0.68041235]\n",
      " [0.28221649 0.85190040 0.41845506 ... 0.79027355 0.81737083 0.80706918]\n",
      " [0.79252577 0.76671034 0.67254037 ... 0.76899695 0.75038761 0.75257730]\n",
      " ...\n",
      " [0.41559702 0.82568806 0.81204110 ... 0.86322188 0.86821705 0.84388804]\n",
      " [0.51935673 0.81127131 0.38842636 ... 0.82749230 0.87678355 0.68232536]\n",
      " [0.24097937 0.78505898 0.34508076 ... 0.80168140 0.79844958 0.78497791]]\n"
     ]
    }
   ],
   "source": [
    "imputed_data = M_mb * X_mb + (1-M_mb) * G_sample\n",
    "print(\"Imputed test data:\")\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.8f}\".format(x)})\n",
    "\n",
    "\n",
    "print(imputed_data.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21.99999809 19.40926170 57.53298187 ... 56.78509521 60.40000153\n",
      "  54.00000000]\n",
      " [25.19999886 70.00000000 40.79679108 ... 60.29999924 62.42041779\n",
      "  62.59999847]\n",
      " [64.80000305 63.50000000 58.09999847 ... 58.90000153 58.10000229\n",
      "  58.89999771]\n",
      " ...\n",
      " [35.55032730 68.00000000 67.59999847 ... 65.10000610 65.69999695\n",
      "  65.09999847]\n",
      " [43.60208130 66.90000153 38.75183487 ... 62.74899673 66.25254059\n",
      "  54.12989426]\n",
      " [21.99999809 64.90000153 35.79999924 ... 61.05063629 61.19999695\n",
      "  61.10000229]]\n"
     ]
    }
   ],
   "source": [
    "# Normalization (0 to 1)\n",
    "renomal = imputed_data \n",
    "\n",
    "for i in range(Dim):\n",
    "    renomal[:,i] = renomal[:,i]* (Max_Val[i]+1e-6)\n",
    "    renomal[:,i] = renomal[:,i]+ Min_Val[i]\n",
    "    \n",
    "print(renomal.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2535, 228])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "renomal.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.5 64-bit ('pytorch_p36': conda)",
   "language": "python",
   "name": "python365jvsc74a57bd067602bcda1a2979e98e24a2c7b4e81c48fa406727758eae6f9b97279c00e3467"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

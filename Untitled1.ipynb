{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c497c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cdebb30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x25f23cf4df8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "008ba9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "# from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "dataset_file = 'V_228.csv'  # 'Letter.csv' for Letter dataset an 'Spam.csv' for Spam dataset\n",
    "use_gpu = False  # set it to True to use GPU and False to use CPU\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# %% System Parameters\n",
    "# 1. Mini batch size\n",
    "mb_size = 128\n",
    "# 2. Missing rate\n",
    "p_miss = 0.2\n",
    "# 3. Hint rate\n",
    "p_hint = 0\n",
    "# 4. Loss Hyperparameters\n",
    "alpha = 10\n",
    "# 5. Train Rate\n",
    "train_rate = 0.8\n",
    "\n",
    "# %% Data\n",
    "\n",
    "# Data generation\n",
    "Data = np.loadtxt(dataset_file, delimiter=\",\", skiprows=1)\n",
    "\n",
    "# Parameters\n",
    "No = len(Data)\n",
    "Dim = len(Data[0, :])\n",
    "\n",
    "# Hidden state dimensions\n",
    "H_Dim1 = Dim\n",
    "H_Dim2 = Dim\n",
    "\n",
    "# Normalization (0 to 1)\n",
    "Min_Val = np.zeros(Dim)\n",
    "Max_Val = np.zeros(Dim)\n",
    "\n",
    "for i in range(Dim):\n",
    "    Min_Val[i] = np.min(Data[:, i])\n",
    "    # print(np.min(Data[:,i]))\n",
    "    Data[:, i] = Data[:, i] - np.min(Data[:, i])\n",
    "    Max_Val[i] = np.max(Data[:, i])\n",
    "    Data[:, i] = Data[:, i] / (np.max(Data[:, i]) + 1e-6)\n",
    "\n",
    "    # %% Missing introducing\n",
    "p_miss_vec = p_miss * np.ones((Dim, 1))\n",
    "\n",
    "Missing = np.zeros((No, Dim))\n",
    "\n",
    "for i in range(Dim):\n",
    "    A = np.random.uniform(0., 1., size=[len(Data), ])\n",
    "    B = A > p_miss_vec[i]\n",
    "    Missing[:, i] = 1. * B\n",
    "\n",
    "# %% Train Test Division\n",
    "\n",
    "idx = np.random.permutation(No)\n",
    "\n",
    "Train_No = int(No * train_rate)\n",
    "Test_No = No - Train_No\n",
    "\n",
    "# Train / Test Features\n",
    "trainX = Data[idx[:Train_No], :]\n",
    "testX = Data[idx[Train_No:], :]\n",
    "\n",
    "# Train / Test Missing Indicators\n",
    "trainM = Missing[idx[:Train_No], :]\n",
    "testM = Missing[idx[Train_No:], :]\n",
    "\n",
    "\n",
    "\n",
    "# Hint Vector Generation\n",
    "def sample_M(m, n, p):\n",
    "    A = np.random.uniform(0., 1., size=[m, n])\n",
    "    B = A > p\n",
    "    C = 1. * B\n",
    "    return C\n",
    "\n",
    "\n",
    "# %% 3. Other functions\n",
    "# Random sample generator for Z\n",
    "def sample_Z(m, n):\n",
    "    return np.random.uniform(0., 0.01, size=[m, n])\n",
    "\n",
    "\n",
    "# Mini-batch generation\n",
    "def sample_idx(m, n):\n",
    "    A = np.random.permutation(m)\n",
    "    idx = A[:n]\n",
    "    return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f665bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(456, 228, bias=True)\n",
    "        self.fc2 = nn.Linear(228, 228, bias=True)\n",
    "        self.fc3 = nn.Linear(228, 228, bias=True)\n",
    "        self.relu = nn.ReLU(True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc(x))\n",
    "        outputs = self.relu(self.fc2(x))\n",
    "        outputs = self.relu(self.fc3(outputs))\n",
    "        return self.sigmoid(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94ed0589",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82cac39b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62609e5a13e848edba87b3b3087cb906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-cb5b82cb32d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mZ_mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_Z\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmb_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mM_mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainM\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmb_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mH_mb1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_M\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmb_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mp_hint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mH_mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mM_mb\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mH_mb1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-ebdeba24bfb6>\u001b[0m in \u001b[0;36msample_M\u001b[1;34m(m, n, p)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;31m# Hint Vector Generation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msample_M\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m     \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m     \u001b[0mB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mA\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mB\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# optimizer 설정\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "optimizer = optim.SGD(model.parameters(), lr=1)\n",
    "\n",
    "nb_epochs = 1000\n",
    "for it in tqdm(range(5000)):\n",
    "    mb_idx = sample_idx(Train_No, mb_size)\n",
    "    X_mb = trainX[mb_idx, :]\n",
    "\n",
    "    Z_mb = sample_Z(mb_size, Dim)\n",
    "    M_mb = trainM[mb_idx, :]\n",
    "    H_mb1 = sample_M(mb_size, Dim, 1 - p_hint)\n",
    "    H_mb = M_mb * H_mb1\n",
    "\n",
    "    New_X_mb = M_mb * X_mb + (1 - M_mb) * Z_mb  # Missing Data Introduce\n",
    "\n",
    "    X_mb = torch.tensor(X_mb)\n",
    "    M_mb = torch.tensor(M_mb)\n",
    "    H_mb = torch.tensor(H_mb)\n",
    "    New_X_mb = torch.tensor(New_X_mb)\n",
    "    \n",
    "    # H(x) 계산\n",
    "    x = torch.cat(dim=1, tensors=[New_X_mb, M_mb])\n",
    "    x = x.float()\n",
    "    hypothesis = model(x)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c151099",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch1",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
